import streamlit as st
from openai import OpenAI
import requests


# page_icon="<UNK>" åç»­å¯ä»¥åŠ å…¥å›¾ç‰‡
st.set_page_config(page_title="NeuraLink", page_icon="<UNK>", layout="centered")

st.title("NeuraLink å¿ƒçµçº½å¸¦")

api_key = "sk-68ec4223332248a4bf9e74e9e582247b"
api_url = "https://api.deepseek.com"

#æ–‡æœ¬è¾“å…¥
prompt = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜æˆ–ç‚¹å‡»ä¸‹æ–¹è¯­éŸ³: ","")

#ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
audio_file = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶(wav/mp3/m4a)",type=["wav","mp3","m4a"])

if st.button("ğŸ¤ å¼€å§‹è¯†åˆ«ï¼ˆWhisperï¼‰") and audio_file is not None:
    import whisper
    model = whisper.load_model("base")
    st.info("è¯†åˆ«ä¸­,è¯·ç¨ç­‰...")
    result = model.transcribe(audio_file.read())
    prompt = result["text"]
    st.success(f"è¯†åˆ«ç»“æœ: {prompt}")

# ä¸AIäº¤äº’
# if prompt:
#     # ä½ å¯ä»¥æ›¿æ¢ä¸ºä½ è‡ªå·±çš„LLMæ¨¡å‹è°ƒç”¨æ–¹å¼ "sk-68ec4223332248a4bf9e74e9e582247b"
#     client = openai.OpenAI(api_key="sk-68ec4223332248a4bf9e74e9e582247b")
#     with st.spinner("AI æ­£åœ¨æ€è€ƒä¸­..."):
#         response = client.chat.completions.create(
#             model = "deepseek-R1",
#             messages=[
#                 {"role":"user","content":prompt}
#             ]
#         )
#         answer = response.choices[0].message.content
#         st.markdown(f"ğŸ¤– **AIå›å¤ï¼š**\n\n{answer}")


if prompt:
    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")

    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": "You are a helpful assistant"},
            {"role": "user", "content": "Hello"},
        ],
        stream=True
    )

    print(response.choices[0].message.content)