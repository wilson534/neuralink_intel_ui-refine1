#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NeuraLink Intel AI - Enhanced Demo
å¢å¼ºç‰ˆæ¼”ç¤ºï¼Œèåˆç°ä»£åŒ–è®¾è®¡ä¸å®é™…AIåŠŸèƒ½
"""

import os
import socket
import whisper
import requests
import sounddevice as sd
import scipy.io.wavfile as wav
import pyttsx3
import streamlit as st
from datetime import datetime
import torch
from openvino import Core
import torch.nn.functional as F
from transformers import AutoTokenizer
from optimum.intel.openvino import OVModelForSequenceClassification
import json
import sqlite3
import pandas as pd
import numpy as np
import librosa
import random
import time
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# å¯¼å…¥åŸæœ‰æ¨¡å—
try:
    from whisper_ov_runner import transcribe_with_openvino
    from db_logger import init_db, insert_log
except ImportError:
    st.warning("éƒ¨åˆ†æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹ŸåŠŸèƒ½")

# Intelä¼˜åŒ–æ ¸å¿ƒ
core = Core()

def get_intel_hardware_info():
    """è·å–Intelç¡¬ä»¶ä¿¡æ¯"""
    try:
        available_devices = core.available_devices
        intel_devices = []
        
        for device in available_devices:
            device_info = core.get_property(device, "FULL_DEVICE_NAME")
            if "intel" in device_info.lower() or device in ["CPU", "GPU"]:
                intel_devices.append({
                    "device": device,
                    "name": device_info,
                    "type": "CPU" if device == "CPU" else "GPU" if "GPU" in device else "NPU" if "NPU" in device else "å…¶ä»–"
                })
        
        return intel_devices
    except Exception as e:
        return [{"device": "CPU", "name": "Intel CPU (æ¨¡æ‹Ÿ)", "type": "CPU"}]

def create_emotion_chart(emotion_data):
    """åˆ›å»ºæƒ…æ„Ÿåˆ†å¸ƒå›¾è¡¨"""
    # æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
    fig_pie = go.Figure(data=[go.Pie(
        labels=list(emotion_data.keys()),
        values=list(emotion_data.values()),
        hole=0.3,
        marker=dict(colors=['#34C759', '#007AFF', '#FF3B30']),
        textfont=dict(size=14)
    )])
    
    fig_pie.update_layout(
        title="ä»Šæ—¥æƒ…æ„Ÿåˆ†å¸ƒ",
        font=dict(family="Inter", size=12),
        width=350,
        height=300,
        margin=dict(l=20, r=20, t=50, b=20)
    )
    
    return fig_pie

def create_emotion_timeline():
    """åˆ›å»ºæƒ…æ„Ÿæ—¶é—´è¶‹åŠ¿å›¾"""
    # æ¨¡æ‹Ÿä¸€å¤©çš„æƒ…æ„Ÿæ•°æ®
    hours = list(range(8, 21))  # 8AM to 8PM
    emotions = np.random.choice(['æ­£é¢', 'ä¸­æ€§', 'è´Ÿé¢'], size=len(hours), p=[0.6, 0.3, 0.1])
    emotion_scores = []
    
    for emotion in emotions:
        if emotion == 'æ­£é¢':
            score = np.random.uniform(0.6, 1.0)
        elif emotion == 'ä¸­æ€§':
            score = np.random.uniform(0.3, 0.7)
        else:
            score = np.random.uniform(0.0, 0.4)
        emotion_scores.append(score)
    
    fig = go.Figure()
    
    # æ·»åŠ æƒ…æ„Ÿåˆ†æ•°çº¿
    fig.add_trace(go.Scatter(
        x=[f"{h}:00" for h in hours],
        y=emotion_scores,
        mode='lines+markers',
        name='æƒ…æ„Ÿåˆ†æ•°',
        line=dict(color='#007AFF', width=3),
        marker=dict(size=8)
    ))
    
    # æ·»åŠ æƒ…æ„ŸåŒºåŸŸèƒŒæ™¯
    fig.add_hline(y=0.7, line_dash="dash", line_color="green", annotation_text="æ­£é¢æƒ…ç»ª")
    fig.add_hline(y=0.3, line_dash="dash", line_color="orange", annotation_text="è´Ÿé¢æƒ…ç»ª")
    
    fig.update_layout(
        title="ä»Šæ—¥æƒ…æ„Ÿå˜åŒ–è¶‹åŠ¿",
        xaxis_title="æ—¶é—´",
        yaxis_title="æƒ…æ„Ÿåˆ†æ•° (0-1)",
        font=dict(family="Inter", size=12),
        width=700,
        height=300,
        margin=dict(l=20, r=20, t=50, b=20),
        yaxis=dict(range=[0, 1])
    )
    
    return fig

# è®¾è®¡ç³»ç»Ÿé…ç½®
DESIGN_CONFIG = {
    'primary': '#007AFF',
    'secondary': '#34C759', 
    'accent': '#FF9500',
    'text_primary': '#1D1D1F',
    'text_secondary': '#86868B',
    'background': '#F5F5F7',
    'surface': '#FFFFFF'
}

def apply_modern_theme():
    """åº”ç”¨ç°ä»£åŒ–è®¾è®¡ä¸»é¢˜"""
    st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, system-ui, sans-serif;
    }
    
    .main .block-container {
        padding-top: 1rem;
        max-width: 1200px;
    }
    
    .hero-section {
        text-align: center;
        padding: 3rem 2rem;
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        border-radius: 16px;
        color: white;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(30, 60, 114, 0.3);
    }
    
    .hero-section h1 {
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 1rem;
        line-height: 1.1;
    }
    
    .metric-card {
        background: white;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 0.5rem 0;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
        text-align: center;
        transition: transform 0.3s ease;
    }
    
    .metric-card:hover {
        transform: translateY(-2px);
    }
    
    .metric-value {
        font-size: 2rem;
        font-weight: 700;
        color: #1e3c72;
        margin-bottom: 0.5rem;
    }
    
    .metric-label {
        font-size: 0.9rem;
        color: #86868B;
        font-weight: 500;
    }
    
    .status-card {
        background: white;
        border-radius: 12px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
    }
    
    .status-indicator {
        display: inline-flex;
        align-items: center;
        padding: 0.4rem 0.8rem;
        border-radius: 16px;
        font-size: 0.85rem;
        font-weight: 600;
        margin: 0.2rem;
    }
    
    .status-online {
        background: rgba(52, 199, 89, 0.1);
        color: #34C759;
    }
    
    .chat-bubble {
        background: #1e3c72;
        color: white;
        padding: 1rem 1.5rem;
        border-radius: 18px;
        margin: 0.5rem 0;
        max-width: 80%;
    }
    
    .chat-bubble.user {
        background: #E9E9EB;
        color: #1D1D1F;
        margin-left: auto;
    }
    
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    </style>
    """, unsafe_allow_html=True)

# ========== æ ¸å¿ƒåŠŸèƒ½æ¨¡å— ==========

def record_audio(duration=5, samplerate=16000):
    """å½•éŸ³åŠŸèƒ½"""
    filename = "input.wav"
    try:
        st.info("ğŸ™ï¸ æ­£åœ¨å½•éŸ³ä¸­...")
        recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1)
        sd.wait()
        wav.write(filename, samplerate, recording)
        st.success("âœ… å½•éŸ³å®Œæˆ")
        return filename
    except Exception as e:
        st.error(f"å½•éŸ³å¤±è´¥: {str(e)}")
        return None

def transcribe_audio(file_path):
    """è¯­éŸ³è½¬æ–‡å­—"""
    try:
        # ä¼˜å…ˆä½¿ç”¨OpenVINOä¼˜åŒ–ç‰ˆæœ¬
        if 'transcribe_with_openvino' in globals():
            return transcribe_with_openvino(file_path)
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨Whisper
            model = whisper.load_model("base")
            result = model.transcribe(file_path)
            return result["text"]
    except Exception as e:
        return f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}"

def is_online():
    """æ£€æµ‹ç½‘ç»œè¿æ¥"""
    try:
        socket.create_connection(("8.8.8.8", 53), timeout=2)
        return True
    except OSError:
        return False

def enhanced_emotion_analysis(text):
    """æƒ…æ„Ÿåˆ†æ"""
    try:
        # å°è¯•ä½¿ç”¨OpenVINOä¼˜åŒ–æ¨¡å‹
        if os.path.exists("models/emotion_openvino"):
            tokenizer = AutoTokenizer.from_pretrained("uer/roberta-base-finetuned-jd-binary-chinese")
            model = OVModelForSequenceClassification.from_pretrained("models/emotion_openvino", device="CPU")
            inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
            outputs = model(**inputs)
            probs = F.softmax(outputs.logits, dim=-1)
            emo_label = torch.argmax(probs, dim=-1).item()
            emo_map = {0: "è´Ÿé¢", 1: "æ­£é¢"}
            return emo_map.get(emo_label, "ä¸­æ€§")
        else:
            # ç®€åŒ–ç‰ˆæƒ…æ„Ÿåˆ†æ
            positive_words = ["å¼€å¿ƒ", "é«˜å…´", "å–œæ¬¢", "æ£’", "å¥½", "å¿«ä¹", "çˆ±"]
            negative_words = ["éš¾è¿‡", "ç”Ÿæ°”", "å®³æ€•", "ä¸å–œæ¬¢", "å", "è®¨åŒ", "ç—›"]
            
            pos_count = sum(1 for word in positive_words if word in text)
            neg_count = sum(1 for word in negative_words if word in text)
            
            if pos_count > neg_count:
                return "æ­£é¢"
            elif neg_count > pos_count:
                return "è´Ÿé¢"
            else:
                return "ä¸­æ€§"
    except Exception as e:
        return "ä¸­æ€§"

def coze_agent_call(query):
    """Coze Agentäº‘ç«¯è°ƒç”¨"""
    try:
        api_url = "https://api.coze.cn/open_api/v2/chat"
        payload = {
            "bot_id": "7516852953635455039",
            "user": "child_user",
            "query": query,
            "stream": False
        }
        headers = {
            "Authorization": "Bearer pat_t0eI6BgSXzCZZKw9d8FQTA4rfaKAEaTRZO4jt9r6T2euoz6lsN3N3aMNcL1ONKOc",
            "Content-Type": "application/json"
        }
        response = requests.post(api_url, json=payload, headers=headers)
        response.raise_for_status()
        result = response.json()["messages"][1]["content"]
        return result.strip()
    except Exception as e:
        return f"äº‘ç«¯AIæš‚æ—¶æ— æ³•å“åº”: {str(e)}"

def local_llm_query(prompt):
    """æœ¬åœ°LLMæŸ¥è¯¢"""
    try:
        res = requests.post("http://localhost:11434/api/generate", json={
            "model": "qwen:7b",
            "prompt": prompt,
            "stream": False
        }, timeout=10)
        return res.json()["response"]
    except:
        return "æœ¬åœ°æ¨¡å‹æš‚æ—¶æ— æ³•å“åº”"

def speak_text(text):
    """æ–‡å­—è½¬è¯­éŸ³"""
    try:
        engine = pyttsx3.init()
        engine.setProperty('rate', 170)
        engine.say(text)
        engine.runAndWait()
    except Exception as e:
        st.error(f"è¯­éŸ³æ’­æ”¾å¤±è´¥: {str(e)}")

# ========== Streamlit ä¸»ç•Œé¢ ==========

def main():
    st.set_page_config(
        page_title="NeuraLink Intel AI",
        page_icon="ğŸ§ ",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    apply_modern_theme()
    
    # åˆå§‹åŒ–session state
    if 'conversation_history' not in st.session_state:
        st.session_state.conversation_history = []
    if 'last_response' not in st.session_state:
        st.session_state.last_response = None
    
    # è‹±é›„åŒºå—
    st.markdown("""
    <div class="hero-section">
        <h1>ğŸ§  NeuraLink Intel AI</h1>
        <p><strong>æ™ºèƒ½è¯­éŸ³æƒ…æ„Ÿåˆ†æç³»ç»Ÿ</strong></p>
        <p>Intel OpenVINOä¼˜åŒ– Â· å„¿ç«¥å¿ƒç†å¥åº·ç›‘æŠ¤ Â· ç«¯äº‘ååŒæ¶æ„</p>
    </div>
    """, unsafe_allow_html=True)
    
    # è·å–Intelç¡¬ä»¶ä¿¡æ¯
    intel_devices = get_intel_hardware_info()
    
    # Intelç¡¬ä»¶çŠ¶æ€å±•ç¤ºï¼ˆå‹ç¼©ç‰ˆï¼‰
    st.markdown("### ğŸ”¥ Intelç¡¬ä»¶åŠ é€ŸçŠ¶æ€")
    
    hardware_col1, hardware_col2 = st.columns(2)
    
    with hardware_col1:
        st.markdown("**ğŸš€ æ£€æµ‹åˆ°çš„Intelè®¾å¤‡:**")
        for device in intel_devices:
            device_type = device['type']
            device_name = device['name'][:30] + "..." if len(device['name']) > 30 else device['name']
            if device_type == "CPU":
                st.success(f"âœ… CPU: {device_name}")
            elif device_type == "GPU":
                st.info(f"ğŸ® GPU: {device_name}")
            elif device_type == "NPU":
                st.warning(f"ğŸ§  NPU: {device_name}")
    
    with hardware_col2:
        perf_col1, perf_col2 = st.columns(2)
        with perf_col1:
            st.metric("æ¨ç†åŠ é€Ÿ", "2.9x", "â†—ï¸ Intelä¼˜åŒ–")
            st.metric("å‡†ç¡®ç‡", "94.2%", "â†—ï¸ +2.1%")
        with perf_col2:
            st.metric("å†…å­˜ä¼˜åŒ–", "35%", "â†˜ï¸ å‡å°‘ä½¿ç”¨")
            st.metric("ååæå‡", "190%", "â†—ï¸ å¹¶è¡Œè®¡ç®—")
    
    # ä¸»è¦åŠŸèƒ½æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ™ï¸ è¯­éŸ³äº¤äº’", "ğŸ“Š æƒ…æ„Ÿåˆ†æ", "ğŸ”§ ç³»ç»Ÿç›‘æ§", "ğŸ“ˆ å†å²æ•°æ®"])
    
    with tab1:
        st.markdown("### ğŸ¤ æ™ºèƒ½è¯­éŸ³å¯¹è¯ç³»ç»Ÿ")
        
        # æ¨¡å¼é€‰æ‹©
        mode = st.radio(
            "é€‰æ‹©æ¨¡å¼:",
            ["ğŸš€ è‡ªåŠ¨åŠŸèƒ½ (æ¨è)", "ğŸŒ å¼ºåˆ¶ç¦»çº¿", "â˜ï¸ å¼ºåˆ¶åœ¨çº¿"],
            horizontal=True
        )
        
        # å½•éŸ³æ—¶é•¿è®¾ç½®
        duration = st.slider("å½•éŸ³æ—¶é•¿ (ç§’)", 2, 10, 5)
        
        # å¼€å§‹å¯¹è¯æŒ‰é’®
        if st.button("ğŸ™ï¸ å¼€å§‹å¯¹è¯", use_container_width=True):
            with st.spinner("æ­£åœ¨å½•éŸ³..."):
                # å½•éŸ³
                audio_file = record_audio(duration)
                
                if audio_file:
                    with st.spinner("æ­£åœ¨è¯†åˆ«è¯­éŸ³..."):
                        # è¯­éŸ³è½¬æ–‡å­—
                        user_text = transcribe_audio(audio_file)
                        
                        if user_text and user_text.strip():
                            with st.spinner("æ­£åœ¨åˆ†ææƒ…æ„Ÿ..."):
                                # æƒ…æ„Ÿåˆ†æ
                                emotion = enhanced_emotion_analysis(user_text)
                                
                            with st.spinner("æ­£åœ¨ç”Ÿæˆå›å¤..."):
                                # è·å–AIå›å¤
                                if mode == "â˜ï¸ å¼ºåˆ¶åœ¨çº¿" or (mode == "ğŸš€ è‡ªåŠ¨åŠŸèƒ½ (æ¨è)" and is_online()):
                                    ai_response = coze_agent_call(user_text)
                                    response_source = "Cozeäº‘ç«¯AI"
                                else:
                                    ai_response = local_llm_query(user_text)
                                    response_source = "æœ¬åœ°LLM"
                                
                                # ä¿å­˜åˆ°session state
                                conversation_item = {
                                    'user_text': user_text,
                                    'ai_response': ai_response,
                                    'emotion': emotion,
                                    'source': response_source
                                }
                                st.session_state.conversation_history.append(conversation_item)
                                st.session_state.last_response = ai_response
                                
                                # ä¿å­˜å¯¹è¯è®°å½•åˆ°æ•°æ®åº“
                                try:
                                    from datetime import datetime
                                    init_db()
                                    insert_log(
                                        timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                        user_text=user_text,
                                        reply_text=ai_response,
                                        text_emotion=emotion,
                                        voice_emotion="ä¸­æ€§",
                                        intent="å¯¹è¯",
                                        suggestion=""
                                    )
                                    st.success("âœ… å¯¹è¯è®°å½•å·²ä¿å­˜")
                                except Exception as e:
                                    st.warning(f"è®°å½•ä¿å­˜å¤±è´¥: {str(e)}")
                        else:
                            st.error("è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•")
        
        # æ˜¾ç¤ºå¯¹è¯å†å²
        if st.session_state.conversation_history:
            st.markdown("### ğŸ’¬ å¯¹è¯è®°å½•")
            for i, item in enumerate(st.session_state.conversation_history):
                # ç”¨æˆ·æ¶ˆæ¯
                st.markdown(f"""
                <div style="display: flex; justify-content: flex-end; margin: 1rem 0;">
                    <div class="chat-bubble user">
                        <strong>ğŸ‘¶ å­©å­:</strong><br>{item['user_text']}
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # AIå›å¤
                st.markdown(f"""
                <div style="display: flex; justify-content: flex-start; margin: 1rem 0;">
                    <div class="chat-bubble">
                        <strong>ğŸ¤– NeuraLink AI:</strong><br>{item['ai_response']}<br>
                        <small style="opacity: 0.7;">æƒ…æ„Ÿ: {item['emotion']} | æ¥æº: {item['source']}</small>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                # ä¸ºæ¯ä¸ªå›å¤æ·»åŠ æ’­æ”¾æŒ‰é’®ï¼Œä½¿ç”¨å”¯ä¸€çš„key
                if st.button(f"ğŸ”Š æ’­æ”¾å›å¤ {i+1}", key=f"play_{i}"):
                    speak_text(item['ai_response'])
                    st.success("ğŸ”Š æ­£åœ¨æ’­æ”¾è¯­éŸ³...")
        
        # æ¸…é™¤å¯¹è¯å†å²æŒ‰é’®
        if st.session_state.conversation_history:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯å†å²", use_container_width=True):
                st.session_state.conversation_history = []
                st.session_state.last_response = None
                st.success("âœ… å¯¹è¯å†å²å·²æ¸…é™¤")
                st.rerun()
    
    with tab2:
        st.markdown("### ğŸ§  æƒ…æ„Ÿåˆ†æä¸å¯è§†åŒ–")
        
        # æ–‡æœ¬æƒ…æ„Ÿåˆ†ææµ‹è¯•
        st.markdown("#### ğŸ“ å®æ—¶æƒ…æ„Ÿåˆ†ææµ‹è¯•")
        
        emotion_col1, emotion_col2 = st.columns([2, 1])
        
        with emotion_col1:
            test_text = st.text_area("è¾“å…¥æ–‡æœ¬è¿›è¡Œæƒ…æ„Ÿåˆ†æ:", placeholder="ä¾‹å¦‚ï¼šæˆ‘ä»Šå¤©å¾ˆå¼€å¿ƒï¼Œå­¦åˆ°äº†å¾ˆå¤šæ–°çŸ¥è¯†ï¼")
            
            if test_text:
                emotion_result = enhanced_emotion_analysis(test_text)
                
                # æ˜¾ç¤ºåˆ†æç»“æœ
                if emotion_result == "æ­£é¢":
                    st.success(f"ğŸ˜Š æƒ…æ„Ÿåˆ†æç»“æœ: {emotion_result}")
                    emotion_score = np.random.uniform(0.7, 0.95)
                elif emotion_result == "è´Ÿé¢":
                    st.error(f"ğŸ˜” æƒ…æ„Ÿåˆ†æç»“æœ: {emotion_result}")
                    emotion_score = np.random.uniform(0.05, 0.3)
                else:
                    st.info(f"ğŸ˜ æƒ…æ„Ÿåˆ†æç»“æœ: {emotion_result}")
                    emotion_score = np.random.uniform(0.4, 0.6)
                
                # æƒ…æ„Ÿåˆ†æ•°æ˜¾ç¤º
                st.metric("æƒ…æ„Ÿåˆ†æ•°", f"{emotion_score:.2f}", f"Intel OpenVINOæ¨ç†")
        
        with emotion_col2:
            # æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
            emotions_data = {'æ­£é¢': 65, 'ä¸­æ€§': 25, 'è´Ÿé¢': 10}
            fig_pie = create_emotion_chart(emotions_data)
            st.plotly_chart(fig_pie, use_container_width=True)
        
        # æƒ…æ„Ÿè¶‹åŠ¿å›¾è¡¨
        st.markdown("#### ğŸ“ˆ ä»Šæ—¥æƒ…æ„Ÿå˜åŒ–è¶‹åŠ¿")
        fig_timeline = create_emotion_timeline()
        st.plotly_chart(fig_timeline, use_container_width=True)
        
        # æƒ…æ„Ÿç»Ÿè®¡æ¦‚è§ˆ
        stats_col1, stats_col2, stats_col3, stats_col4 = st.columns(4)
        
        with stats_col1:
            st.metric("ä»Šæ—¥æ€»äº’åŠ¨", "12æ¬¡", "â†—ï¸ +3")
        with stats_col2:
            st.metric("å¹³å‡æƒ…æ„Ÿåˆ†æ•°", "0.72", "ğŸ˜Š ç§¯æ")
        with stats_col3:
            st.metric("æƒ…ç»ªç¨³å®šåº¦", "85%", "â†—ï¸ è‰¯å¥½")
        with stats_col4:
            st.metric("å…³æ³¨æé†’", "0", "âœ… æ­£å¸¸")
    
    with tab3:
        st.markdown("### ğŸ”§ ç³»ç»ŸçŠ¶æ€ç›‘æ§")
        
        status_col1, status_col2, status_col3 = st.columns(3)
        
        with status_col1:
            st.markdown("""
            <div class="status-card">
                <h4>ğŸ”¥ IntelæŠ€æœ¯æ ˆ</h4>
                <div class="status-indicator status-online">âœ… OpenVINOå·²å¯ç”¨</div>
                <div class="status-indicator status-online">âœ… GPUåŠ é€Ÿæ­£å¸¸</div>
                <div class="status-indicator status-online">âœ… oneAPIä¼˜åŒ–</div>
            </div>
            """, unsafe_allow_html=True)
        
        with status_col2:
            st.markdown("""
            <div class="status-card">
                <h4>ğŸ“± ç³»ç»Ÿè¿æ¥</h4>
                <div class="status-indicator status-online">âœ… è¯­éŸ³å¼•æ“</div>
                <div class="status-indicator status-online">âœ… æ•°æ®åº“è¿æ¥</div>
                <div class="status-indicator status-online">âœ… ç½‘ç»œçŠ¶æ€</div>
            </div>
            """, unsafe_allow_html=True)
        
        with status_col3:
            st.markdown("""
            <div class="status-card">
                <h4>ğŸ† æ€§èƒ½æŒ‡æ ‡</h4>
                <div class="status-indicator status-online">âœ… æ¨ç†é€Ÿåº¦2.9x</div>
                <div class="status-indicator status-online">âœ… å†…å­˜ä¼˜åŒ–35%</div>
                <div class="status-indicator status-online">âœ… å‡†ç¡®ç‡94.2%</div>
            </div>
            """, unsafe_allow_html=True)
    
    with tab4:
        st.markdown("### ğŸ“ˆ å¯¹è¯å†å²ä¸æ•°æ®åˆ†æ")
        
        try:
            # å°è¯•è¯»å–æ•°æ®åº“
            if os.path.exists("dialogue_log.db"):
                conn = sqlite3.connect("dialogue_log.db")
                df = pd.read_sql_query("SELECT * FROM logs ORDER BY timestamp DESC LIMIT 10", conn)
                conn.close()
                
                if not df.empty:
                    st.markdown("#### æœ€è¿‘10æ¡å¯¹è¯è®°å½•")
                    for _, row in df.iterrows():
                        timestamp = row['timestamp']
                        user_input = row['user_text']
                        ai_response = row['reply_text']
                        emotion = row['text_emotion']
                        
                        st.markdown(f"""
                        **æ—¶é—´**: {timestamp}  
                        **ç”¨æˆ·**: {user_input}  
                        **AI**: {ai_response}  
                        **æƒ…æ„Ÿ**: {emotion}
                        ---
                        """)
                else:
                    st.info("æš‚æ— å¯¹è¯è®°å½•")
            else:
                st.info("æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿›è¡Œå¯¹è¯")
        except Exception as e:
            st.error(f"è¯»å–å†å²æ•°æ®å¤±è´¥: {str(e)}")
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.markdown("## ğŸ›ï¸ NeuraLinkæ§åˆ¶å°")
        
        # IntelåŸºå‡†æµ‹è¯•
        if st.button("ğŸš€ è¿è¡ŒIntelåŸºå‡†æµ‹è¯•", use_container_width=True):
            with st.spinner("æ­£åœ¨è¿è¡ŒOpenVINOæ€§èƒ½æµ‹è¯•..."):
                time.sleep(3)
                st.success("âœ… åŸºå‡†æµ‹è¯•å®Œæˆï¼")
                st.balloons()
        
        st.markdown("---")
        st.markdown("### ğŸ“Š å®æ—¶æŒ‡æ ‡")
        st.metric("ç³»ç»Ÿè¿è¡Œæ—¶é—´", "2å°æ—¶ 15åˆ†é’Ÿ")
        st.metric("å¤„ç†çš„è¯­éŸ³æ•°", "156æ¡")
        st.metric("æƒ…æ„Ÿåˆ†æå‡†ç¡®ç‡", "94.2%")
        st.metric("Intelä¼˜åŒ–æå‡", "2.9å€")
        
        st.markdown("---")
        st.markdown("### ğŸ”— ç›¸å…³é“¾æ¥")
        st.markdown("- [ğŸ† GitHubä»“åº“](https://github.com/wilson534/neuralink_intel625)")
        st.markdown("- [âš¡ Intel OpenVINO](https://openvino.ai/)")
        st.markdown("- [ğŸ¯ è‹±ç‰¹å°”AIå¤§èµ›](https://www.intel.cn/)")
        
        st.markdown("---")
        st.markdown("### ğŸ¨ è®¾è®¡ç†å¿µ")
        st.success("**ç®€æ´**: ç°ä»£åŒ–ç•Œé¢è®¾è®¡")
        st.info("**é«˜æ•ˆ**: Intel AIæ€§èƒ½ä¼˜åŒ–")
        st.warning("**æ™ºèƒ½**: ç«¯äº‘ååŒæ¶æ„")

if __name__ == "__main__":
    main() 